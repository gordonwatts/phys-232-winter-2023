{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We'll use weather data to talk about several methods of using the data, some are packages out of `pypi` and others are builtin. The builtin packages tend to be designed to handle smaller amounts of data.\n",
    "\n",
    "We'll start with data from a weather station in the Capitol hill area of Seattle. Take a look at the `3235995.csv` file. I extracted this from [NOAA yesterday](www.ncdc.noaa.gov/) (using instructions found in your book).\n",
    "\n",
    "First, lets load it up with the normal `csv` package. Use `help(csv)` after you've `import csv` to get some brief help on the package.\n",
    "\n",
    "Here we will load the file, taken straight from our book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('3235995.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = reader.__next__()\n",
    "    print(header)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note each call to `__next__()` grabs the next item. Lets read 5 lines using some trickery and the `enumerate` function for a `for` loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('3235995.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = reader.__next__()\n",
    "    print(header)\n",
    "    for index, row in enumerate(reader):\n",
    "        if index < 5:\n",
    "            print(row)\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an aside, the `__next__` function is what python uses to iterate over any iterable object - like a list or a tuple or anything else similar. If you create you own object with a `__next__` function, then it can also participate in `for` loops, list comprehensions, generator expressions, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now - lets get 1000 entries in the `PRCP` (precipitation) into a single list, `measurements`, which we will then plot.\n",
    "\n",
    "WARNING: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "class"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets make a simple plot of them. We need to think a second of what we want. We want a trend line - as a function of time. We won't do date just yet - lets start with just doing sequence number.\n",
    "\n",
    "This is just a scatter plot, with `(x,y)` being `(sequence number, precipitation)`. We use `matplotlib`, *the* plotting library for python and `jupyter` notebooks, for this - and its `scatter` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.scatter(list(range(0, 1000)), measurements)\n",
    "plt.xlabel('Measurement Number')\n",
    "plt.ylabel('Precipitation (in)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok - we can already see patterns! While the data contains three years, we've only pulled in about 3or 4 years here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `pandas`\n",
    "\n",
    "Pandas is _the way_ to manipulate square data in the python data science eco-system. There are courses taught on this. We are going to go through some very simple stuff here.\n",
    "\n",
    "First, lets read in the whole sample. Note the integration with Jupyter and how it will pretty print!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('3235995.csv')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An amazingly useful, but simple, thing is to look at the list of columns. I'll place this here just for reference..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* The `NaN` are missing (if you look back at our 5 line read-in you'll note they are empty strings) - this forces you to make explicit decisions about missing data, rather than assuming they are zeros. A lesson the whole community learned, repeatedly, the hard way.\n",
    "* The column names are things you can actually reference in the data frame - so titles are important, and spaces aren't great."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make the same plot as we did previously.\n",
    "\n",
    "Note how we can reference the `PRCP` column as `df.PRCP`. You can also do `df['PRCP']` as well. You can even index it by a column number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(list(range(0, len(df))), df.PRCP)\n",
    "plt.xlabel('Measurement Number')\n",
    "plt.ylabel('Precipitation (in)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK - great - can we do anything with the months to try to bring this trend out further?\n",
    "\n",
    "They say you spend most of your time in data science work cleaning your data. It is no different in science. Getting good, well understood, data often feels like 80% of the battle getting to a good result.\n",
    "\n",
    "Here, first, we need the `DATE` column to be a data object that we can manipulate as a date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is basically a string here (and `object`). We want to change it to a date. This is pretty common, so `pandas` has a function to help us. But there are lots of ways to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do things like asking for summaries as a function of year, month, and even day. We do this by creating a new column that splits the components of the date out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['DATE'].apply(lambda x: x.year)\n",
    "df['month'] = df['DATE'].apply(lambda x: x.month)\n",
    "df['day'] = df['DATE'].apply(lambda x: x.day)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take all the measurements for a year and sum them, and then get a yearly rainfall report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year = df.groupby('year')['PRCP'].sum()\n",
    "by_year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make a plot of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year.plot.bar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn\n",
    "\n",
    "Just to give you a quick example of some of the crazy visualizations you can do, lets look at the rain fall by month. We'll use a very nice, and very opinionated, plot library called `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make a plot of accumulation per month, with the years on top of each other so we can see the general trend.\n",
    "\n",
    "1. Group the data by month and year - so we get a sum for each one.\n",
    "   * We have to `reset_index` here because otherwise we get a crash - `pandas` tries to be clever and `seaborn` can't deal with it being clever.\n",
    "1. Use `seaborn` to make a nice plot of the data for each year, but on an axis that is the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "by_month = df.groupby(['year', 'month'])['PRCP'].sum().reset_index()\n",
    "sns.relplot(x='month', y='PRCP', data=by_month, hue=\"year\", kind=\"line\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97ee99713355a295790cf988e930f7ce05360b418008be67aa4c33ddf991f00c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
